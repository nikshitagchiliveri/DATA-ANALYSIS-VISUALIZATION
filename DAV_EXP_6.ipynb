{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPqm1C2A6x5YLEiIk2r3xes",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikshitagchiliveri/DATA-ANALYSIS-VISUALIZATION/blob/main/DAV_EXP_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpuuijjQ8b6y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/sample.csv')"
      ],
      "metadata": {
        "id": "kp2Wxl9E8etZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "wjDLPsG98mkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "5LvdgDZL84vY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. REPLACING NAME OF COMPANY WITH AN AUTHOR_ID"
      ],
      "metadata": {
        "id": "-aVFwp0gAw94"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['author_id'] = df['author_id'].replace({\n",
        "    'ChaseSupport': '112233',\n",
        "    'VirginTrains': '442233',\n",
        "    'AppleSupport': '552233',\n",
        "    'British_Airways': '662233',\n",
        "    'O2': '772233',\n",
        "    'comcastcares': '882233',\n",
        "    'sprintcare': '992233',\n",
        "    'Ask_Spectrum': '002233',\n",
        "    'Tesco': '110033',\n",
        "    'HPSupport': '119933',\n",
        "    'UPSHelp': '116633',\n",
        "    'SpotifyCares' : '123456',\n",
        "    'SouthwestAir' : '789012',\n",
        "})"
      ],
      "metadata": {
        "id": "XS5IRqio89of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['author_id'].unique()"
      ],
      "metadata": {
        "id": "idjnOoXE9prn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. LOWER CASING"
      ],
      "metadata": {
        "id": "7aO4gzPHChuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.applymap(lambda string : string.lower() if isinstance(string,str) else string)"
      ],
      "metadata": {
        "id": "8LM7N2tB_V-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. REMOVE PUNCTUATIONS"
      ],
      "metadata": {
        "id": "vO2GTXJKITX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "def remove_puctuations(text):\n",
        "  if isinstance(text,str):\n",
        "    return text.translate(str.maketrans('','',string.punctuation))\n",
        "  else:\n",
        "    return text\n",
        "df = df.applymap(remove_puctuations)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "UzkCiti1CgNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. REMOVE STOPWORDS"
      ],
      "metadata": {
        "id": "hsiW3kcVIZwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\", \".join(stopwords.words('english'))\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "def remove_stopwords(text):\n",
        "    \"\"\"Custom function to remove the stopwords\"\"\"\n",
        "    if isinstance(text, str):\n",
        "        # Use STOPWORDS set instead of stopwords\n",
        "        return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
        "    return text\n",
        "\n",
        "for column in df.select_dtypes(include=['object']).columns:\n",
        "    df[column] = df[column].apply(remove_stopwords)"
      ],
      "metadata": {
        "id": "gDdkoA62FfEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. REMOVING NULL VALUES"
      ],
      "metadata": {
        "id": "niduKSVsIcg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "rNIrUImdF5eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "1GOULhtJH3Er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. REMOVE EMOJIS"
      ],
      "metadata": {
        "id": "ZDbOs1WtLFnV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def remove_emoji(string):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', string)\n",
        "df['text'] = df['text'].apply(remove_emoji)"
      ],
      "metadata": {
        "id": "r3gE4IsrI5GD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. REMOVE EMOTICONS"
      ],
      "metadata": {
        "id": "2n6YLMnyL1xO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_emoticons(text):\n",
        "    \"\"\"Removes common emoticons from the input text.\"\"\"\n",
        "    # Escape special characters in EMOTICONS list for regex\n",
        "    escaped_emoticons = [re.escape(emoticon) for emoticon in EMOTICONS]\n",
        "    emoticon_pattern = re.compile(u'(' + u'|'.join(escaped_emoticons) + u')')\n",
        "    return emoticon_pattern.sub(r'', text)\n",
        "\n",
        "EMOTICONS = [\n",
        "    \":)\", \":(\", \":D\", \":-D\", \":P\", \":-P\", \";)\", \";-)\", \":O\", \":-O\",\n",
        "    \":(\", \":-(\", \":’(\", \":’)\", \":/\", \":-/\", \":|\", \":-|\",\n",
        "    \":$\", \":-$\", \":'(\", \":')\", \":*\", \":-*\", \">:(\" ,\n",
        "]\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: remove_emoticons(x))"
      ],
      "metadata": {
        "id": "_HAUptvpKjQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. STEMMING"
      ],
      "metadata": {
        "id": "x3kD3HH0OkTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the two columns if they exist\n",
        "if \"text_wo_stopfreq\" in df.columns and \"text_wo_stopfreqrare\" in df.columns:\n",
        "    df.drop([\"text_wo_stopfreq\", \"text_wo_stopfreqrare\"], axis=1, inplace=True)\n",
        "else:\n",
        "    print(\"Columns 'text_wo_stopfreq' and/or 'text_wo_stopfreqrare' not found in DataFrame.\")\n",
        "\n",
        "# Continue with the rest of your code\n",
        "# Import the PorterStemmer class from nltk.stem\n",
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def stem_words(text):\n",
        "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
        "\n",
        "df[\"text_stemmed\"] = df[\"text\"].apply(lambda text: stem_words(text))\n",
        "df.head()"
      ],
      "metadata": {
        "id": "W6WRHJfeLUrV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. LEMMATIZATION"
      ],
      "metadata": {
        "id": "ukM3DHGnOnQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def lemmatize_words(text):\n",
        "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
        "\n",
        "df[\"text_lemmatized\"] = df[\"text\"].apply(lambda text: lemmatize_words(text))\n",
        "df.head()"
      ],
      "metadata": {
        "id": "wwJCES_BNInt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. REMOVAL OF URLs"
      ],
      "metadata": {
        "id": "oRv-eRt7i9ZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_urls(text):\n",
        "    \"\"\"Removes URLs from the input text.\"\"\"\n",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url_pattern.sub(r'', text)\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: remove_urls(x))"
      ],
      "metadata": {
        "id": "B1sPe3ogO2BG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "9pplpU6UPzje"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}